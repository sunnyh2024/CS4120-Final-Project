{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranformer model with PyTorch\n",
    "\n",
    "This notebook creates and trains a tranformer with encoder-decoder architecture using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import json\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from spotify import SpotifyClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Creating the model__\n",
    "\n",
    "Creating the layers for model. The multi-head attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output\n",
    "    \n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Encoder Layer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Decoder Layer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loading in the data from the challenge set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a batch size for our experiments\n",
    "BATCH_SIZE = 35\n",
    "# define a percentage of the data to use for training\n",
    "SPLIT_PC = .90\n",
    "\n",
    "# open the file and convert it to json\n",
    "f = open('spotify_million_playlist_dataset_challenge/challenge_set.json')\n",
    "js = json.load(f)\n",
    "playlists = js['playlists']\n",
    "\n",
    "titles = []\n",
    "tracks = []\n",
    "\n",
    "# process and add the playlist names and tracks to lists\n",
    "for playlist in playlists:\n",
    "    if not playlist['tracks'] or 'name' not in playlist:\n",
    "        continue\n",
    "    titles.append(playlist['name'].lower()) \n",
    "    tracks.append(' '.join(track['track_uri'] for track in playlist['tracks']))\n",
    "\n",
    "END = int(len(titles)*SPLIT_PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom tokenizer for separating tracks (just separates by spaces)\n",
    "# we tried using tokenizers from libraries, but they split up the track URIs, which we didn't want\n",
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        self.dictionary = {}\n",
    "        self.reverse_dictionary = {}\n",
    "\n",
    "        # Add the padding token\n",
    "        self.dictionary['<UNK>'] = 0\n",
    "        self.reverse_dictionary[0] = '<UNK>'\n",
    "        self.cur_token = 1\n",
    "\n",
    "    def fit_on_texts(self, sentences):\n",
    "        for sentence in sentences:\n",
    "            self.tokenize(sentence)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        for token in text.split():\n",
    "            if token not in self.dictionary:\n",
    "                self.dictionary[token] = self.cur_token\n",
    "                self.reverse_dictionary[self.cur_token] = token\n",
    "                self.cur_token += 1\n",
    "\n",
    "    def character_to_token(self, character):\n",
    "        return self.dictionary[character]\n",
    "\n",
    "    def token_to_character(self, token):\n",
    "        return self.reverse_dictionary[token]\n",
    "    \n",
    "    def texts_to_sequences(self, sentences):\n",
    "        sequences = []\n",
    "        for sentence in sentences:\n",
    "            cur_sentence = []\n",
    "            for token in sentence.split():\n",
    "                if token not in self.dictionary:\n",
    "                    cur_sentence.append(self.dictionary['<UNK>'])\n",
    "                else:\n",
    "                    cur_sentence.append(self.dictionary[token])\n",
    "            sequences.append(cur_sentence)\n",
    "        return sequences\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tokenize and pad titles and tracks__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizes the given sentences and returns a list of lists of the tokens\n",
    "def tokenize(sentences):\n",
    "    text_tokenizer = Tokenizer()\n",
    "    text_tokenizer.fit_on_texts(sentences)\n",
    "    return text_tokenizer.texts_to_sequences(sentences), text_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2], [3, 4], [5, 6], [7], [8, 9], [10], [11], [12, 13], [14]]\n",
      "Vocabularies: 2487, 63998\n",
      "Max lengths: 9, 100\n",
      "[[ 1  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0]\n",
      " [ 3  4  0  0  0  0  0  0  0]\n",
      " [ 5  6  0  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  0  0  0  0  0]\n",
      " [ 8  9  0  0  0  0  0  0  0]\n",
      " [10  0  0  0  0  0  0  0  0]\n",
      " [11  0  0  0  0  0  0  0  0]\n",
      " [12 13  0  0  0  0  0  0  0]\n",
      " [14  0  0  0  0  0  0  0  0]]\n",
      "Tensor shapes: torch.Size([7000, 9]), torch.Size([7000, 100])\n"
     ]
    }
   ],
   "source": [
    "# tokenize titles and tracks, and also get the tokenizers\n",
    "titles_tokens, title_tokenizer = tokenize(titles)\n",
    "tracks_tokens, track_tokenizer = tokenize(tracks)\n",
    "print(titles_tokens[:10])\n",
    "\n",
    "title_vocab = title_tokenizer.size() + 1\n",
    "track_vocab = track_tokenizer.size() + 1\n",
    "print(f'Vocabularies: {title_vocab}, {track_vocab}')\n",
    "\n",
    "max_title_length = int(len(max(titles_tokens, key=len)))\n",
    "max_track_length = int(len(max(tracks_tokens, key=len)))\n",
    "print(f'Max lengths: {max_title_length}, {max_track_length}')\n",
    "\n",
    "pad_titles = pad_sequences(titles_tokens, max_title_length, padding = \"post\")\n",
    "pad_tracks = pad_sequences(tracks_tokens, max_track_length, padding = \"post\")\n",
    "print(pad_titles[:10])\n",
    "\n",
    "title_tensor = torch.LongTensor(pad_titles)\n",
    "tracks_tensor = torch.LongTensor(pad_tracks)\n",
    "print(f'Tensor shapes: {title_tensor.shape}, {tracks_tensor.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a data generator for training__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator for title and track tensors\n",
    "def data_generator(titles: torch.LongTensor, tracks: torch.LongTensor, batch_size: int = BATCH_SIZE):\n",
    "    i = 0\n",
    "    while True:\n",
    "        # return the current batch\n",
    "        yield titles[i: i + batch_size], tracks[i: i + batch_size]\n",
    "        \n",
    "        i += batch_size\n",
    "        # if we reach the end of the tensor, start from the beginning again\n",
    "        if i >= len(titles):\n",
    "            i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = 100\n",
    "dropout = 0.1\n",
    "\n",
    "# initialize a Transformer model (from above) using the declared params\n",
    "transformer = Transformer(title_vocab, track_vocab, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training__\n",
    "\n",
    "This took about 30 sec for 10 epochs with batch size of 35 on a M2 Macbook Air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 11.17990493774414\n",
      "Epoch: 2, Loss: 11.23021125793457\n",
      "Epoch: 3, Loss: 11.131558418273926\n",
      "Epoch: 4, Loss: 11.186010360717773\n",
      "Epoch: 5, Loss: 11.110666275024414\n",
      "Epoch: 6, Loss: 11.137246131896973\n",
      "Epoch: 7, Loss: 11.171707153320312\n",
      "Epoch: 8, Loss: 10.95988655090332\n",
      "Epoch: 9, Loss: 11.113736152648926\n",
      "Epoch: 10, Loss: 10.92345905303955\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "transformer.train()\n",
    "generator = data_generator(title_tensor, tracks_tensor)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    titles, tracks = next(generator)\n",
    "    output = transformer(titles, tracks)\n",
    "    loss = criterion(output.contiguous().view(-1, track_vocab), tracks.contiguous().view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Evaluating and generating predictions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tracks': [{'album': {'album_type': 'album',\n",
       "    'artists': [{'external_urls': {'spotify': 'https://open.spotify.com/artist/0Y5tJX1MQlPlqiwlOH1tJY'},\n",
       "      'href': 'https://api.spotify.com/v1/artists/0Y5tJX1MQlPlqiwlOH1tJY',\n",
       "      'id': '0Y5tJX1MQlPlqiwlOH1tJY',\n",
       "      'name': 'Travis Scott',\n",
       "      'type': 'artist',\n",
       "      'uri': 'spotify:artist:0Y5tJX1MQlPlqiwlOH1tJY'}],\n",
       "    'available_markets': ['AR',\n",
       "     'AU',\n",
       "     'AT',\n",
       "     'BE',\n",
       "     'BO',\n",
       "     'BR',\n",
       "     'BG',\n",
       "     'CA',\n",
       "     'CL',\n",
       "     'CO',\n",
       "     'CR',\n",
       "     'CY',\n",
       "     'CZ',\n",
       "     'DK',\n",
       "     'DO',\n",
       "     'DE',\n",
       "     'EC',\n",
       "     'EE',\n",
       "     'SV',\n",
       "     'FI',\n",
       "     'FR',\n",
       "     'GR',\n",
       "     'GT',\n",
       "     'HN',\n",
       "     'HK',\n",
       "     'HU',\n",
       "     'IS',\n",
       "     'IE',\n",
       "     'IT',\n",
       "     'LV',\n",
       "     'LT',\n",
       "     'LU',\n",
       "     'MY',\n",
       "     'MT',\n",
       "     'MX',\n",
       "     'NL',\n",
       "     'NZ',\n",
       "     'NI',\n",
       "     'NO',\n",
       "     'PA',\n",
       "     'PY',\n",
       "     'PE',\n",
       "     'PH',\n",
       "     'PL',\n",
       "     'PT',\n",
       "     'SG',\n",
       "     'SK',\n",
       "     'ES',\n",
       "     'SE',\n",
       "     'CH',\n",
       "     'TW',\n",
       "     'TR',\n",
       "     'UY',\n",
       "     'US',\n",
       "     'GB',\n",
       "     'AD',\n",
       "     'LI',\n",
       "     'MC',\n",
       "     'ID',\n",
       "     'JP',\n",
       "     'TH',\n",
       "     'VN',\n",
       "     'RO',\n",
       "     'IL',\n",
       "     'ZA',\n",
       "     'MA',\n",
       "     'DZ',\n",
       "     'TN',\n",
       "     'IN',\n",
       "     'BY',\n",
       "     'KZ',\n",
       "     'MD',\n",
       "     'UA',\n",
       "     'AL',\n",
       "     'BA',\n",
       "     'HR',\n",
       "     'ME',\n",
       "     'MK',\n",
       "     'RS',\n",
       "     'SI',\n",
       "     'KR',\n",
       "     'BD',\n",
       "     'PK',\n",
       "     'LK',\n",
       "     'GH',\n",
       "     'KE',\n",
       "     'NG',\n",
       "     'TZ',\n",
       "     'UG',\n",
       "     'AG',\n",
       "     'AM',\n",
       "     'BS',\n",
       "     'BB',\n",
       "     'BZ',\n",
       "     'BT',\n",
       "     'BW',\n",
       "     'BF',\n",
       "     'CV',\n",
       "     'CW',\n",
       "     'DM',\n",
       "     'FJ',\n",
       "     'GM',\n",
       "     'GE',\n",
       "     'GD',\n",
       "     'GW',\n",
       "     'GY',\n",
       "     'HT',\n",
       "     'JM',\n",
       "     'KI',\n",
       "     'LS',\n",
       "     'LR',\n",
       "     'MW',\n",
       "     'MV',\n",
       "     'ML',\n",
       "     'MH',\n",
       "     'FM',\n",
       "     'NA',\n",
       "     'NR',\n",
       "     'NE',\n",
       "     'PW',\n",
       "     'PG',\n",
       "     'WS',\n",
       "     'SM',\n",
       "     'ST',\n",
       "     'SN',\n",
       "     'SC',\n",
       "     'SL',\n",
       "     'SB',\n",
       "     'KN',\n",
       "     'LC',\n",
       "     'VC',\n",
       "     'SR',\n",
       "     'TL',\n",
       "     'TO',\n",
       "     'TT',\n",
       "     'TV',\n",
       "     'VU',\n",
       "     'AZ',\n",
       "     'BN',\n",
       "     'BI',\n",
       "     'KH',\n",
       "     'CM',\n",
       "     'TD',\n",
       "     'KM',\n",
       "     'GQ',\n",
       "     'SZ',\n",
       "     'GA',\n",
       "     'GN',\n",
       "     'KG',\n",
       "     'LA',\n",
       "     'MO',\n",
       "     'MR',\n",
       "     'MN',\n",
       "     'NP',\n",
       "     'RW',\n",
       "     'TG',\n",
       "     'UZ',\n",
       "     'ZW',\n",
       "     'BJ',\n",
       "     'MG',\n",
       "     'MU',\n",
       "     'MZ',\n",
       "     'AO',\n",
       "     'CI',\n",
       "     'DJ',\n",
       "     'ZM',\n",
       "     'CD',\n",
       "     'CG',\n",
       "     'TJ',\n",
       "     'VE',\n",
       "     'ET',\n",
       "     'XK'],\n",
       "    'external_urls': {'spotify': 'https://open.spotify.com/album/42WVQWuf1teDysXiOupIZt'},\n",
       "    'href': 'https://api.spotify.com/v1/albums/42WVQWuf1teDysXiOupIZt',\n",
       "    'id': '42WVQWuf1teDysXiOupIZt',\n",
       "    'images': [{'height': 640,\n",
       "      'url': 'https://i.scdn.co/image/ab67616d0000b273f54b99bf27cda88f4a7403ce',\n",
       "      'width': 640},\n",
       "     {'height': 300,\n",
       "      'url': 'https://i.scdn.co/image/ab67616d00001e02f54b99bf27cda88f4a7403ce',\n",
       "      'width': 300},\n",
       "     {'height': 64,\n",
       "      'url': 'https://i.scdn.co/image/ab67616d00004851f54b99bf27cda88f4a7403ce',\n",
       "      'width': 64}],\n",
       "    'name': 'Birds In The Trap Sing McKnight',\n",
       "    'release_date': '2016-09-16',\n",
       "    'release_date_precision': 'day',\n",
       "    'total_tracks': 14,\n",
       "    'type': 'album',\n",
       "    'uri': 'spotify:album:42WVQWuf1teDysXiOupIZt'},\n",
       "   'artists': [{'external_urls': {'spotify': 'https://open.spotify.com/artist/0Y5tJX1MQlPlqiwlOH1tJY'},\n",
       "     'href': 'https://api.spotify.com/v1/artists/0Y5tJX1MQlPlqiwlOH1tJY',\n",
       "     'id': '0Y5tJX1MQlPlqiwlOH1tJY',\n",
       "     'name': 'Travis Scott',\n",
       "     'type': 'artist',\n",
       "     'uri': 'spotify:artist:0Y5tJX1MQlPlqiwlOH1tJY'}],\n",
       "   'available_markets': ['AR',\n",
       "    'AU',\n",
       "    'AT',\n",
       "    'BE',\n",
       "    'BO',\n",
       "    'BR',\n",
       "    'BG',\n",
       "    'CA',\n",
       "    'CL',\n",
       "    'CO',\n",
       "    'CR',\n",
       "    'CY',\n",
       "    'CZ',\n",
       "    'DK',\n",
       "    'DO',\n",
       "    'DE',\n",
       "    'EC',\n",
       "    'EE',\n",
       "    'SV',\n",
       "    'FI',\n",
       "    'FR',\n",
       "    'GR',\n",
       "    'GT',\n",
       "    'HN',\n",
       "    'HK',\n",
       "    'HU',\n",
       "    'IS',\n",
       "    'IE',\n",
       "    'IT',\n",
       "    'LV',\n",
       "    'LT',\n",
       "    'LU',\n",
       "    'MY',\n",
       "    'MT',\n",
       "    'MX',\n",
       "    'NL',\n",
       "    'NZ',\n",
       "    'NI',\n",
       "    'NO',\n",
       "    'PA',\n",
       "    'PY',\n",
       "    'PE',\n",
       "    'PH',\n",
       "    'PL',\n",
       "    'PT',\n",
       "    'SG',\n",
       "    'SK',\n",
       "    'ES',\n",
       "    'SE',\n",
       "    'CH',\n",
       "    'TW',\n",
       "    'TR',\n",
       "    'UY',\n",
       "    'US',\n",
       "    'GB',\n",
       "    'AD',\n",
       "    'LI',\n",
       "    'MC',\n",
       "    'ID',\n",
       "    'JP',\n",
       "    'TH',\n",
       "    'VN',\n",
       "    'RO',\n",
       "    'IL',\n",
       "    'ZA',\n",
       "    'MA',\n",
       "    'DZ',\n",
       "    'TN',\n",
       "    'IN',\n",
       "    'BY',\n",
       "    'KZ',\n",
       "    'MD',\n",
       "    'UA',\n",
       "    'AL',\n",
       "    'BA',\n",
       "    'HR',\n",
       "    'ME',\n",
       "    'MK',\n",
       "    'RS',\n",
       "    'SI',\n",
       "    'KR',\n",
       "    'BD',\n",
       "    'PK',\n",
       "    'LK',\n",
       "    'GH',\n",
       "    'KE',\n",
       "    'NG',\n",
       "    'TZ',\n",
       "    'UG',\n",
       "    'AG',\n",
       "    'AM',\n",
       "    'BS',\n",
       "    'BB',\n",
       "    'BZ',\n",
       "    'BT',\n",
       "    'BW',\n",
       "    'BF',\n",
       "    'CV',\n",
       "    'CW',\n",
       "    'DM',\n",
       "    'FJ',\n",
       "    'GM',\n",
       "    'GE',\n",
       "    'GD',\n",
       "    'GW',\n",
       "    'GY',\n",
       "    'HT',\n",
       "    'JM',\n",
       "    'KI',\n",
       "    'LS',\n",
       "    'LR',\n",
       "    'MW',\n",
       "    'MV',\n",
       "    'ML',\n",
       "    'MH',\n",
       "    'FM',\n",
       "    'NA',\n",
       "    'NR',\n",
       "    'NE',\n",
       "    'PW',\n",
       "    'PG',\n",
       "    'WS',\n",
       "    'SM',\n",
       "    'ST',\n",
       "    'SN',\n",
       "    'SC',\n",
       "    'SL',\n",
       "    'SB',\n",
       "    'KN',\n",
       "    'LC',\n",
       "    'VC',\n",
       "    'SR',\n",
       "    'TL',\n",
       "    'TO',\n",
       "    'TT',\n",
       "    'TV',\n",
       "    'VU',\n",
       "    'AZ',\n",
       "    'BN',\n",
       "    'BI',\n",
       "    'KH',\n",
       "    'CM',\n",
       "    'TD',\n",
       "    'KM',\n",
       "    'GQ',\n",
       "    'SZ',\n",
       "    'GA',\n",
       "    'GN',\n",
       "    'KG',\n",
       "    'LA',\n",
       "    'MO',\n",
       "    'MR',\n",
       "    'MN',\n",
       "    'NP',\n",
       "    'RW',\n",
       "    'TG',\n",
       "    'UZ',\n",
       "    'ZW',\n",
       "    'BJ',\n",
       "    'MG',\n",
       "    'MU',\n",
       "    'MZ',\n",
       "    'AO',\n",
       "    'CI',\n",
       "    'DJ',\n",
       "    'ZM',\n",
       "    'CD',\n",
       "    'CG',\n",
       "    'TJ',\n",
       "    'VE',\n",
       "    'ET',\n",
       "    'XK'],\n",
       "   'disc_number': 1,\n",
       "   'duration_ms': 243836,\n",
       "   'explicit': True,\n",
       "   'external_ids': {'isrc': 'USSM11607555'},\n",
       "   'external_urls': {'spotify': 'https://open.spotify.com/track/6gBFPUFcJLzWGx4lenP6h2'},\n",
       "   'href': 'https://api.spotify.com/v1/tracks/6gBFPUFcJLzWGx4lenP6h2',\n",
       "   'id': '6gBFPUFcJLzWGx4lenP6h2',\n",
       "   'is_local': False,\n",
       "   'name': 'goosebumps',\n",
       "   'popularity': 87,\n",
       "   'preview_url': 'https://p.scdn.co/mp3-preview/5c45fee2743d39984ed2c1e2493d04a42d626f81?cid=744e625455ed47afa39d44c224c3eb34',\n",
       "   'track_number': 9,\n",
       "   'type': 'track',\n",
       "   'uri': 'spotify:track:6gBFPUFcJLzWGx4lenP6h2'}]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the model to eval mode\n",
    "transformer.eval()\n",
    "output = transformer(title_tensor[1:2], tracks_tensor[1:2])\n",
    "\n",
    "# Get the track with the highest probability, then convert the tokens back to URIs\n",
    "output = output.view(-1, track_vocab).argmax(1)\n",
    "output = [track_tokenizer.token_to_character(i) for i in output.numpy()]\n",
    "print(output)\n",
    "\n",
    "output = list(set(output))\n",
    "\n",
    "# use Spotify API to get the song names\n",
    "client = SpotifyClient()\n",
    "client.get_song_titles(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
