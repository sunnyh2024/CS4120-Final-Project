{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model\n",
    "\n",
    "This notebook contains the Recurrent Neural Network for generating playlists. It was built using layers provided by Keras.\n",
    "\n",
    "To use this model, change the ```input_title``` variable in the last code box to the desired playlist title, then run all cells in the notebook. After the first run of the notebook, new playlists can be generated just by editing and running the last code box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Input, TimeDistributed, Dense, Activation, RepeatVector, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file and load it as a json\n",
    "f = open('spotify_million_playlist_dataset_challenge/challenge_set.json')\n",
    "js = json.load(f)\n",
    "playlists = js['playlists']\n",
    "\n",
    "# process the json data and add to the appropriate list or dict\n",
    "titles = []\n",
    "tracks = []\n",
    "trackID_to_name = {}\n",
    "\n",
    "for playlist in playlists:\n",
    "    if not playlist['tracks'] or 'name' not in playlist:\n",
    "        continue\n",
    "    titles.append(playlist['name'].lower())\n",
    "    tracks.append(' '.join(track['track_uri'].split(\":\")[2] for track in playlist['tracks']))\n",
    "    for track in playlist['tracks']:\n",
    "        trackID_to_name[track['track_uri'].split(\":\")[2].lower()] = track['track_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses the keras tokenizer to tokenize a list of sentences\n",
    "# returns the tokenized sentences and the tokenizer\n",
    "def tokenize(sentences):\n",
    "    text_tokenizer = Tokenizer()\n",
    "    text_tokenizer.fit_on_texts(sentences)\n",
    "    return text_tokenizer.texts_to_sequences(sentences), text_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad the tracks and titles\n",
    "titles_tokens, title_tokenizer = tokenize(titles)\n",
    "tracks_tokens, track_tokenizer = tokenize(tracks)\n",
    "\n",
    "title_vocab = len(title_tokenizer.word_index) + 1\n",
    "track_vocab = len(track_tokenizer.word_index) + 1\n",
    "\n",
    "max_title_length = int(len(max(titles_tokens, key=len)))\n",
    "max_track_length = int(len(max(tracks_tokens, key=len)))\n",
    "\n",
    "pad_titles = pad_sequences(titles_tokens, max_title_length, padding = \"post\")\n",
    "pad_tracks = pad_sequences(tracks_tokens, max_track_length, padding = \"post\")\n",
    "\n",
    "pad_titles = pad_titles.reshape(*pad_titles.shape, 1)\n",
    "pad_tracks = pad_tracks.reshape(*pad_tracks.shape, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the layers of the modle\n",
    "input_sequence = Input(shape=(max_title_length,))\n",
    "embedding = Embedding(input_dim=title_vocab, output_dim=128,)(input_sequence)\n",
    "encoder = LSTM(64, return_sequences=False)(embedding)\n",
    "r_vec = RepeatVector(max_track_length)(encoder)\n",
    "decoder = LSTM(64, return_sequences=True, dropout=0.2)(r_vec)\n",
    "logits = TimeDistributed(Dense(track_vocab))(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 9)]               0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 9, 128)            285440    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " repeat_vector (RepeatVecto  (None, 100, 64)           0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100, 64)           33024     \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 100, 63997)        4159805   \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 100, 63997)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4527677 (17.27 MB)\n",
      "Trainable params: 4527677 (17.27 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# creating the model with summary\n",
    "enc_dec_model = Model(input_sequence, Activation('softmax')(logits))\n",
    "enc_dec_model.compile(loss=sparse_categorical_crossentropy,\n",
    "              optimizer=Adam(1e-3),\n",
    "              metrics=['accuracy'])\n",
    "enc_dec_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 18:15:47.249474: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp_10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 121s 506ms/step - loss: 5.9307 - accuracy: 0.6171\n",
      "Epoch 2/3\n",
      "234/234 [==============================] - 120s 512ms/step - loss: 4.4616 - accuracy: 0.6200\n",
      "Epoch 3/3\n",
      "234/234 [==============================] - 118s 506ms/step - loss: 4.4552 - accuracy: 0.6200\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model_results = enc_dec_model.fit(pad_titles, pad_tracks, batch_size=30, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the output sequence and converts it back to a sentence using the given tokenizer\n",
    "def logits_to_sentence(logits, tokenizer):\n",
    "    index_to_words = {idx: word for word, idx in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = 'empty'\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argsort(logits, axis=1)[:, -1 * random.randrange(2, 10)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 554ms/step\n",
      "Input Title: summer\n",
      "Predicted Tracklist: 5dnfhmqgr128gmy2tc5cej 5dnfhmqgr128gmy2tc5cej 5dnfhmqgr128gmy2tc5cej 5dnfhmqgr128gmy2tc5cej 5dnfhmqgr128gmy2tc5cej 5dnfhmqgr128gmy2tc5cej 5dnfhmqgr128gmy2tc5cej 5dnfhmqgr128gmy2tc5cej 5dnfhmqgr128gmy2tc5cej 1xznggdreh1oqq0xzbwxa3 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 7kxjtscq5nl1loytl7xaws 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 5nqbuaeteogdd6hhcre0dz 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb 05zackzw8ybrq3efgifsnb\n",
      "Extracted Track Names: {'Springsteen', 'One Dance', 'HUMBLE.', '679 (feat. Remy Boyz)', 'Ignition - Remix'}\n"
     ]
    }
   ],
   "source": [
    "# uses the given title to generate a playlist for that title\n",
    "def predict_tracklist(title, enc_dec_model, title_tokenizer, track_tokenizer, max_title_length, max_track_length):\n",
    "    input_title_tokens = title_tokenizer.texts_to_sequences([title.lower()])\n",
    "    pad_input_title = pad_sequences(input_title_tokens, max_title_length, padding=\"post\")\n",
    "    pad_input_title = pad_input_title.reshape(*pad_input_title.shape, 1)\n",
    "\n",
    "    predictions = enc_dec_model.predict(pad_input_title)[0]\n",
    "\n",
    "    predicted_sentence = logits_to_sentence(predictions, track_tokenizer)\n",
    "\n",
    "    track_names = set()\n",
    "    for track_id in predicted_sentence.split():\n",
    "        track_names.add(trackID_to_name.get(track_id, \"Unknown Track Name\"))\n",
    "\n",
    "    return predicted_sentence, track_names\n",
    "\n",
    "# change input_title here to generate for other playlist titles\n",
    "input_title = \"summer\"\n",
    "predicted_sentence, track_names = predict_tracklist(input_title, enc_dec_model, title_tokenizer, track_tokenizer, max_title_length, max_track_length)\n",
    "\n",
    "print(f\"Input Title: {input_title}\")\n",
    "print(f\"Predicted Tracklist: {predicted_sentence}\")\n",
    "print(f\"Extracted Track Names: {track_names}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
